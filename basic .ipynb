{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>271f93f4</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-20.769371, -20.769434, -25.906025, -25.90602...</td>\n",
       "      <td>[-29.288746, -29.712593, -28.884804, -28.88480...</td>\n",
       "      <td>b51d18b5</td>\n",
       "      <td>36.9034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-26.673811, -23.666162, -27.622442, -28.31768...</td>\n",
       "      <td>[-24.557735, -26.97868, -27.622442, -29.073456...</td>\n",
       "      <td>31da1a04</td>\n",
       "      <td>34.4751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-24.989119, -27.755224, -25.817074, -24.98927...</td>\n",
       "      <td>[-27.755173, -26.732174, -28.124943, -31.83772...</td>\n",
       "      <td>56929c16</td>\n",
       "      <td>41.1769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-17.146641, -17.146572, -17.994583, -19.44553...</td>\n",
       "      <td>[-25.733608, -24.472507, -24.710424, -22.77215...</td>\n",
       "      <td>525ab75c</td>\n",
       "      <td>35.7829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-24.020853, -23.551275, -27.18819, -29.126434...</td>\n",
       "      <td>[-28.702518, -33.563324, -29.571918, -29.12643...</td>\n",
       "      <td>192f56eb</td>\n",
       "      <td>43.3007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-21.397552, -19.753859, -23.426783, -24.65221...</td>\n",
       "      <td>[-26.72291, -27.418192, -27.787899, -25.774536...</td>\n",
       "      <td>3aac67cd</td>\n",
       "      <td>44.624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-22.020813, -22.020864, -20.345379, -18.07829...</td>\n",
       "      <td>[-29.018383, -26.519661, -26.214916, -27.16346...</td>\n",
       "      <td>161a6860</td>\n",
       "      <td>39.5067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-21.112206, -21.638832, -25.436468, -23.22255...</td>\n",
       "      <td>[-27.30481, -28.415202999999998, -24.634125, -...</td>\n",
       "      <td>3c794f0c</td>\n",
       "      <td>41.8544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-23.864258, -27.755791, -26.047226, -24.62014...</td>\n",
       "      <td>[-23.626272, -24.620068, -28.546, -26.363146, ...</td>\n",
       "      <td>86730f0d</td>\n",
       "      <td>45.2909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-20.558899, -21.328135, -19.585205, -19.71788...</td>\n",
       "      <td>[-29.127485, -30.40094, -28.741528, -24.380484...</td>\n",
       "      <td>e356f7a3</td>\n",
       "      <td>34.7715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-28.282215, -27.896156, -25.882795, -25.88279...</td>\n",
       "      <td>[-31.608845, -29.110111, -32.851887, -32.85188...</td>\n",
       "      <td>87592c38</td>\n",
       "      <td>43.782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-21.345695, -21.345734, -21.166676, -20.65056...</td>\n",
       "      <td>[-26.343246, -25.143326, -23.374924, -22.92943...</td>\n",
       "      <td>1c18a39e</td>\n",
       "      <td>45.3568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[-19.261189, -19.812914, -23.263891, -25.41662...</td>\n",
       "      <td>[-25.149176, -26.271551, -27.560766, -27.91539...</td>\n",
       "      <td>a210f335</td>\n",
       "      <td>38.7812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-25.950783, -26.571512, -22.943153, -21.94372...</td>\n",
       "      <td>[-29.623671, -30.093336, -27.594606, -29.17827...</td>\n",
       "      <td>958d155f</td>\n",
       "      <td>42.5145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[-21.557806, -22.084446, -19.187838, -16.91901...</td>\n",
       "      <td>[-22.084385, -24.583221, -30.13426, -26.461437...</td>\n",
       "      <td>6d81d201</td>\n",
       "      <td>37.2802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[-27.674824, -26.335936, -26.979677, -31.19679...</td>\n",
       "      <td>[-28.044491, -27.67487, -29.704073, -31.196793...</td>\n",
       "      <td>75126706</td>\n",
       "      <td>41.7973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[-26.345797, -26.05139, -26.650714999999998, -...</td>\n",
       "      <td>[-30.488308, -26.05139, -22.924503, -22.924503...</td>\n",
       "      <td>112a6cfa</td>\n",
       "      <td>38.0669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[-15.745731, -14.04358, -14.653421, -16.111671...</td>\n",
       "      <td>[-26.538006, -27.522421, -29.906204, -27.52253...</td>\n",
       "      <td>a29662a4</td>\n",
       "      <td>39.6636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[-14.6148, -14.6148, -16.136662, -15.342532, -...</td>\n",
       "      <td>[-26.656, -26.656, -22.534969, -25.496277, -26...</td>\n",
       "      <td>bd1a1bdf</td>\n",
       "      <td>37.6866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[-16.015327, -16.015327, -14.87892, -16.899502...</td>\n",
       "      <td>[-23.789312, -23.789312, -24.021, -23.78941499...</td>\n",
       "      <td>31e37d93</td>\n",
       "      <td>40.296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[-19.261448, -19.671938, -20.712574, -20.10284...</td>\n",
       "      <td>[-27.220249, -28.671318, -30.910847, -25.69265...</td>\n",
       "      <td>76b8d446</td>\n",
       "      <td>39.234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[-10.99748, -11.994458, -11.209444, -11.209444...</td>\n",
       "      <td>[-12.792967, -18.622711, -13.816119, -13.81611...</td>\n",
       "      <td>958d42a8</td>\n",
       "      <td>40.3904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[-31.042643, -31.60326, -32.202568, -30.51619,...</td>\n",
       "      <td>[-34.297188, -32.846218, -30.019676, -29.10457...</td>\n",
       "      <td>70830858</td>\n",
       "      <td>43.7895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[-27.995171, -23.865738, -22.165567, -22.76487...</td>\n",
       "      <td>[-28.785341, -30.620794, -27.625595, -25.40263...</td>\n",
       "      <td>faf2c49e</td>\n",
       "      <td>42.5891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[-26.390104, -28.888929, -28.888929, -27.72913...</td>\n",
       "      <td>[-25.230265, -26.706038, -26.706038, -24.45200...</td>\n",
       "      <td>02314c59</td>\n",
       "      <td>41.0303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>[-21.309566, -20.840015, -22.515629, -21.15040...</td>\n",
       "      <td>[-26.709482, -26.709555, -27.998783, -29.51327...</td>\n",
       "      <td>84fe7f94</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>[-20.215452, -19.626303, -18.941971, -19.07453...</td>\n",
       "      <td>[-22.867964, -23.2917, -23.737179, -23.511507,...</td>\n",
       "      <td>04e6f331</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>[-23.334843, -25.328943, -26.213058, -25.90830...</td>\n",
       "      <td>[-31.073734, -29.581106, -33.572594, -32.87739...</td>\n",
       "      <td>92c90853</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>[-25.666952, -25.942781, -24.64403, -24.174473...</td>\n",
       "      <td>[-25.666952, -25.667017, -25.942844, -27.81134...</td>\n",
       "      <td>660a98a7</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>[-19.281799, -17.870247, -18.202303, -18.78553...</td>\n",
       "      <td>[-23.890778, -26.988886, -30.357046, -27.63272...</td>\n",
       "      <td>89670962</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>[-18.215658, -17.459957, -17.564053, -19.68742...</td>\n",
       "      <td>[-25.064114, -26.697582, -27.986814, -27.64621...</td>\n",
       "      <td>9d586019</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>[-17.248318, -16.214254, -15.532733, -15.95249...</td>\n",
       "      <td>[-21.718636, -24.217484, -24.443178, -25.15756...</td>\n",
       "      <td>5f49ea3b</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>[-24.588913, -24.588951, -24.85627, -23.363632...</td>\n",
       "      <td>[-29.853745, -28.110779, -23.363598, -23.83325...</td>\n",
       "      <td>968e1414</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>[-24.811455, -25.078775, -24.055771, -20.69634...</td>\n",
       "      <td>[-29.161131, -27.222977, -28.737434, -30.07641...</td>\n",
       "      <td>389d7eaf</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>[-19.654991, -24.04619, -21.321854, -18.991802...</td>\n",
       "      <td>[-26.099377, -25.814627, -29.197536, -32.12015...</td>\n",
       "      <td>65ca9e76</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>[-19.815434, -20.994926, -19.954279, -17.52577...</td>\n",
       "      <td>[-23.761044, -23.760979, -22.737862, -24.92068...</td>\n",
       "      <td>a09cae27</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>[-18.443468, -17.668488, -21.296959, -21.79350...</td>\n",
       "      <td>[-24.349022, -24.12347, -23.689157, -27.645437...</td>\n",
       "      <td>00c5b3e0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>[-21.710968, -21.162241, -24.336622, -22.92503...</td>\n",
       "      <td>[-21.710968, -23.840113, -26.023041, -23.60220...</td>\n",
       "      <td>7f9df2b0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>[-20.982038, -17.765095, -17.460377, -17.36119...</td>\n",
       "      <td>[-28.291798, -27.30752, -22.995605, -25.124796...</td>\n",
       "      <td>a2303efc</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>[-13.383982, -12.767777, -14.186477, -17.88528...</td>\n",
       "      <td>[-24.233467, -24.233543, -23.185856, -23.38561...</td>\n",
       "      <td>cb62e5cb</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>[-22.688837, -21.349943, -22.898233, -22.89827...</td>\n",
       "      <td>[-30.048372, -31.63204, -34.326054, -32.231392...</td>\n",
       "      <td>9ff1e0f0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>[-22.613323, -20.475389, -19.295786, -19.15894...</td>\n",
       "      <td>[-24.401331, -23.91861, -23.461304, -26.983082...</td>\n",
       "      <td>39fd995a</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>[-16.95768, -21.794147, -24.581587, -24.819641...</td>\n",
       "      <td>[-23.27611, -29.501163, -35.945621, -29.501307...</td>\n",
       "      <td>544d0681</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>[-5.64585, -7.455446, -8.050229, -8.050307, -8...</td>\n",
       "      <td>[-14.208546, -13.801398, -14.709263, -15.80631...</td>\n",
       "      <td>cb0319fc</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>[-28.554342, -26.37149, -25.17157, -25.171608,...</td>\n",
       "      <td>[-26.055567, -27.394543, -28.55442, -30.389864...</td>\n",
       "      <td>d86deb2b</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>[-25.950792, -26.255636, -23.834808, -25.09588...</td>\n",
       "      <td>[-30.093304, -28.75441, -27.240044, -29.178288...</td>\n",
       "      <td>cdee905a</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>[-25.31617, -25.895485, -24.773212, -23.779497...</td>\n",
       "      <td>[-26.516129, -29.122847, -29.568417, -30.53455...</td>\n",
       "      <td>2539742b</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>[-14.463013, -15.378237, -14.535848, -14.83290...</td>\n",
       "      <td>[-25.165276, -24.682676, -25.41721, -30.026262...</td>\n",
       "      <td>2ea3c9f1</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>[-19.997332, -18.115284, -15.673027, -14.26133...</td>\n",
       "      <td>[-20.727669, -23.175728, -20.576469, -20.28193...</td>\n",
       "      <td>9cadda28</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>[-14.200315, -15.292111, -15.60808, -18.324097...</td>\n",
       "      <td>[-24.02071, -24.455181, -24.020878, -23.607269...</td>\n",
       "      <td>8376a077</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>[-30.999878, -29.976866, -28.233906, -29.50732...</td>\n",
       "      <td>[-27.847719, -28.233864, -24.712077999999998, ...</td>\n",
       "      <td>04e11240</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>[-25.31155, -26.511555, -28.694487, -27.180115...</td>\n",
       "      <td>[-29.563713, -28.290375, -26.839405, -28.29046...</td>\n",
       "      <td>c7d6f6f8</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>[-18.141895, -18.141844, -19.01737, -19.701599...</td>\n",
       "      <td>[-25.305355, -29.387701, -28.963863, -26.16023...</td>\n",
       "      <td>bba1a0f1</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>[-22.455633, -25.794661, -26.954567, -22.83354...</td>\n",
       "      <td>[-26.070356, -22.093737, -21.577662, -24.53376...</td>\n",
       "      <td>7f66bb44</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>[-19.909191, -20.678406, -20.208834, -18.42441...</td>\n",
       "      <td>[-24.44487, -24.956001, -27.722103, -26.078417...</td>\n",
       "      <td>9d8f326c</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "0     [-27.878360999999998, -27.15416, -28.668615, -...   \n",
       "1     [-12.242375, -14.920304999999999, -14.920363, ...   \n",
       "2     [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3     [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4     [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "5     [-20.769371, -20.769434, -25.906025, -25.90602...   \n",
       "6     [-26.673811, -23.666162, -27.622442, -28.31768...   \n",
       "7     [-24.989119, -27.755224, -25.817074, -24.98927...   \n",
       "8     [-17.146641, -17.146572, -17.994583, -19.44553...   \n",
       "9     [-24.020853, -23.551275, -27.18819, -29.126434...   \n",
       "10    [-21.397552, -19.753859, -23.426783, -24.65221...   \n",
       "11    [-22.020813, -22.020864, -20.345379, -18.07829...   \n",
       "12    [-21.112206, -21.638832, -25.436468, -23.22255...   \n",
       "13    [-23.864258, -27.755791, -26.047226, -24.62014...   \n",
       "14    [-20.558899, -21.328135, -19.585205, -19.71788...   \n",
       "15    [-28.282215, -27.896156, -25.882795, -25.88279...   \n",
       "16    [-21.345695, -21.345734, -21.166676, -20.65056...   \n",
       "17    [-19.261189, -19.812914, -23.263891, -25.41662...   \n",
       "18    [-25.950783, -26.571512, -22.943153, -21.94372...   \n",
       "19    [-21.557806, -22.084446, -19.187838, -16.91901...   \n",
       "20    [-27.674824, -26.335936, -26.979677, -31.19679...   \n",
       "21    [-26.345797, -26.05139, -26.650714999999998, -...   \n",
       "22    [-15.745731, -14.04358, -14.653421, -16.111671...   \n",
       "23    [-14.6148, -14.6148, -16.136662, -15.342532, -...   \n",
       "24    [-16.015327, -16.015327, -14.87892, -16.899502...   \n",
       "25    [-19.261448, -19.671938, -20.712574, -20.10284...   \n",
       "26    [-10.99748, -11.994458, -11.209444, -11.209444...   \n",
       "27    [-31.042643, -31.60326, -32.202568, -30.51619,...   \n",
       "28    [-27.995171, -23.865738, -22.165567, -22.76487...   \n",
       "29    [-26.390104, -28.888929, -28.888929, -27.72913...   \n",
       "...                                                 ...   \n",
       "1574  [-21.309566, -20.840015, -22.515629, -21.15040...   \n",
       "1575  [-20.215452, -19.626303, -18.941971, -19.07453...   \n",
       "1576  [-23.334843, -25.328943, -26.213058, -25.90830...   \n",
       "1577  [-25.666952, -25.942781, -24.64403, -24.174473...   \n",
       "1578  [-19.281799, -17.870247, -18.202303, -18.78553...   \n",
       "1579  [-18.215658, -17.459957, -17.564053, -19.68742...   \n",
       "1580  [-17.248318, -16.214254, -15.532733, -15.95249...   \n",
       "1581  [-24.588913, -24.588951, -24.85627, -23.363632...   \n",
       "1582  [-24.811455, -25.078775, -24.055771, -20.69634...   \n",
       "1583  [-19.654991, -24.04619, -21.321854, -18.991802...   \n",
       "1584  [-19.815434, -20.994926, -19.954279, -17.52577...   \n",
       "1585  [-18.443468, -17.668488, -21.296959, -21.79350...   \n",
       "1586  [-21.710968, -21.162241, -24.336622, -22.92503...   \n",
       "1587  [-20.982038, -17.765095, -17.460377, -17.36119...   \n",
       "1588  [-13.383982, -12.767777, -14.186477, -17.88528...   \n",
       "1589  [-22.688837, -21.349943, -22.898233, -22.89827...   \n",
       "1590  [-22.613323, -20.475389, -19.295786, -19.15894...   \n",
       "1591  [-16.95768, -21.794147, -24.581587, -24.819641...   \n",
       "1592  [-5.64585, -7.455446, -8.050229, -8.050307, -8...   \n",
       "1593  [-28.554342, -26.37149, -25.17157, -25.171608,...   \n",
       "1594  [-25.950792, -26.255636, -23.834808, -25.09588...   \n",
       "1595  [-25.31617, -25.895485, -24.773212, -23.779497...   \n",
       "1596  [-14.463013, -15.378237, -14.535848, -14.83290...   \n",
       "1597  [-19.997332, -18.115284, -15.673027, -14.26133...   \n",
       "1598  [-14.200315, -15.292111, -15.60808, -18.324097...   \n",
       "1599  [-30.999878, -29.976866, -28.233906, -29.50732...   \n",
       "1600  [-25.31155, -26.511555, -28.694487, -27.180115...   \n",
       "1601  [-18.141895, -18.141844, -19.01737, -19.701599...   \n",
       "1602  [-22.455633, -25.794661, -26.954567, -22.83354...   \n",
       "1603  [-19.909191, -20.678406, -20.208834, -18.42441...   \n",
       "\n",
       "                                                 band_2        id inc_angle  \\\n",
       "0     [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913   43.9239   \n",
       "1     [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd   38.1562   \n",
       "2     [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0   45.2859   \n",
       "3     [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18   43.8306   \n",
       "4     [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4   35.6256   \n",
       "5     [-29.288746, -29.712593, -28.884804, -28.88480...  b51d18b5   36.9034   \n",
       "6     [-24.557735, -26.97868, -27.622442, -29.073456...  31da1a04   34.4751   \n",
       "7     [-27.755173, -26.732174, -28.124943, -31.83772...  56929c16   41.1769   \n",
       "8     [-25.733608, -24.472507, -24.710424, -22.77215...  525ab75c   35.7829   \n",
       "9     [-28.702518, -33.563324, -29.571918, -29.12643...  192f56eb   43.3007   \n",
       "10    [-26.72291, -27.418192, -27.787899, -25.774536...  3aac67cd    44.624   \n",
       "11    [-29.018383, -26.519661, -26.214916, -27.16346...  161a6860   39.5067   \n",
       "12    [-27.30481, -28.415202999999998, -24.634125, -...  3c794f0c   41.8544   \n",
       "13    [-23.626272, -24.620068, -28.546, -26.363146, ...  86730f0d   45.2909   \n",
       "14    [-29.127485, -30.40094, -28.741528, -24.380484...  e356f7a3   34.7715   \n",
       "15    [-31.608845, -29.110111, -32.851887, -32.85188...  87592c38    43.782   \n",
       "16    [-26.343246, -25.143326, -23.374924, -22.92943...  1c18a39e   45.3568   \n",
       "17    [-25.149176, -26.271551, -27.560766, -27.91539...  a210f335   38.7812   \n",
       "18    [-29.623671, -30.093336, -27.594606, -29.17827...  958d155f   42.5145   \n",
       "19    [-22.084385, -24.583221, -30.13426, -26.461437...  6d81d201   37.2802   \n",
       "20    [-28.044491, -27.67487, -29.704073, -31.196793...  75126706   41.7973   \n",
       "21    [-30.488308, -26.05139, -22.924503, -22.924503...  112a6cfa   38.0669   \n",
       "22    [-26.538006, -27.522421, -29.906204, -27.52253...  a29662a4   39.6636   \n",
       "23    [-26.656, -26.656, -22.534969, -25.496277, -26...  bd1a1bdf   37.6866   \n",
       "24    [-23.789312, -23.789312, -24.021, -23.78941499...  31e37d93    40.296   \n",
       "25    [-27.220249, -28.671318, -30.910847, -25.69265...  76b8d446    39.234   \n",
       "26    [-12.792967, -18.622711, -13.816119, -13.81611...  958d42a8   40.3904   \n",
       "27    [-34.297188, -32.846218, -30.019676, -29.10457...  70830858   43.7895   \n",
       "28    [-28.785341, -30.620794, -27.625595, -25.40263...  faf2c49e   42.5891   \n",
       "29    [-25.230265, -26.706038, -26.706038, -24.45200...  02314c59   41.0303   \n",
       "...                                                 ...       ...       ...   \n",
       "1574  [-26.709482, -26.709555, -27.998783, -29.51327...  84fe7f94        na   \n",
       "1575  [-22.867964, -23.2917, -23.737179, -23.511507,...  04e6f331        na   \n",
       "1576  [-31.073734, -29.581106, -33.572594, -32.87739...  92c90853        na   \n",
       "1577  [-25.666952, -25.667017, -25.942844, -27.81134...  660a98a7        na   \n",
       "1578  [-23.890778, -26.988886, -30.357046, -27.63272...  89670962        na   \n",
       "1579  [-25.064114, -26.697582, -27.986814, -27.64621...  9d586019        na   \n",
       "1580  [-21.718636, -24.217484, -24.443178, -25.15756...  5f49ea3b        na   \n",
       "1581  [-29.853745, -28.110779, -23.363598, -23.83325...  968e1414        na   \n",
       "1582  [-29.161131, -27.222977, -28.737434, -30.07641...  389d7eaf        na   \n",
       "1583  [-26.099377, -25.814627, -29.197536, -32.12015...  65ca9e76        na   \n",
       "1584  [-23.761044, -23.760979, -22.737862, -24.92068...  a09cae27        na   \n",
       "1585  [-24.349022, -24.12347, -23.689157, -27.645437...  00c5b3e0        na   \n",
       "1586  [-21.710968, -23.840113, -26.023041, -23.60220...  7f9df2b0        na   \n",
       "1587  [-28.291798, -27.30752, -22.995605, -25.124796...  a2303efc        na   \n",
       "1588  [-24.233467, -24.233543, -23.185856, -23.38561...  cb62e5cb        na   \n",
       "1589  [-30.048372, -31.63204, -34.326054, -32.231392...  9ff1e0f0        na   \n",
       "1590  [-24.401331, -23.91861, -23.461304, -26.983082...  39fd995a        na   \n",
       "1591  [-23.27611, -29.501163, -35.945621, -29.501307...  544d0681        na   \n",
       "1592  [-14.208546, -13.801398, -14.709263, -15.80631...  cb0319fc        na   \n",
       "1593  [-26.055567, -27.394543, -28.55442, -30.389864...  d86deb2b        na   \n",
       "1594  [-30.093304, -28.75441, -27.240044, -29.178288...  cdee905a        na   \n",
       "1595  [-26.516129, -29.122847, -29.568417, -30.53455...  2539742b        na   \n",
       "1596  [-25.165276, -24.682676, -25.41721, -30.026262...  2ea3c9f1        na   \n",
       "1597  [-20.727669, -23.175728, -20.576469, -20.28193...  9cadda28        na   \n",
       "1598  [-24.02071, -24.455181, -24.020878, -23.607269...  8376a077        na   \n",
       "1599  [-27.847719, -28.233864, -24.712077999999998, ...  04e11240        na   \n",
       "1600  [-29.563713, -28.290375, -26.839405, -28.29046...  c7d6f6f8        na   \n",
       "1601  [-25.305355, -29.387701, -28.963863, -26.16023...  bba1a0f1        na   \n",
       "1602  [-26.070356, -22.093737, -21.577662, -24.53376...  7f66bb44        na   \n",
       "1603  [-24.44487, -24.956001, -27.722103, -26.078417...  9d8f326c        na   \n",
       "\n",
       "      is_iceberg  \n",
       "0              0  \n",
       "1              0  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  \n",
       "5              1  \n",
       "6              1  \n",
       "7              0  \n",
       "8              0  \n",
       "9              0  \n",
       "10             1  \n",
       "11             0  \n",
       "12             1  \n",
       "13             1  \n",
       "14             0  \n",
       "15             0  \n",
       "16             0  \n",
       "17             0  \n",
       "18             0  \n",
       "19             1  \n",
       "20             0  \n",
       "21             1  \n",
       "22             0  \n",
       "23             1  \n",
       "24             0  \n",
       "25             1  \n",
       "26             1  \n",
       "27             0  \n",
       "28             1  \n",
       "29             0  \n",
       "...          ...  \n",
       "1574           0  \n",
       "1575           0  \n",
       "1576           0  \n",
       "1577           0  \n",
       "1578           0  \n",
       "1579           0  \n",
       "1580           0  \n",
       "1581           0  \n",
       "1582           0  \n",
       "1583           0  \n",
       "1584           0  \n",
       "1585           0  \n",
       "1586           0  \n",
       "1587           0  \n",
       "1588           0  \n",
       "1589           0  \n",
       "1590           0  \n",
       "1591           0  \n",
       "1592           0  \n",
       "1593           0  \n",
       "1594           0  \n",
       "1595           0  \n",
       "1596           0  \n",
       "1597           0  \n",
       "1598           0  \n",
       "1599           0  \n",
       "1600           0  \n",
       "1601           0  \n",
       "1602           0  \n",
       "1603           0  \n",
       "\n",
       "[1604 rows x 5 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['band_1', 'band_2', 'id', 'inc_angle', 'is_iceberg'], dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5625"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['band_1'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5625"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75*75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    851\n",
       "1    753\n",
       "Name: is_iceberg, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_iceberg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1604, 5)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "na         133\n",
       "34.4721     23\n",
       "42.5591     16\n",
       "36.1061     15\n",
       "33.6352     15\n",
       "39.234      13\n",
       "38.4755     11\n",
       "45.2814     11\n",
       "39.2166     11\n",
       "39.9784     11\n",
       "34.4709     10\n",
       "42.559      10\n",
       "45.2859     10\n",
       "39.2325      9\n",
       "35.7863      9\n",
       "40.7129      9\n",
       "34.4718      9\n",
       "37.6877      9\n",
       "38.4591      9\n",
       "40.7118      9\n",
       "37.6866      8\n",
       "35.2957      8\n",
       "38.0736      8\n",
       "42.5644      7\n",
       "43.2611      7\n",
       "36.9034      7\n",
       "40.3904      7\n",
       "38.8594      7\n",
       "42.5598      6\n",
       "34.9664      6\n",
       "          ... \n",
       "43.8456      1\n",
       "45.2858      1\n",
       "37.338       1\n",
       "43.9847      1\n",
       "41.2023      1\n",
       "39.6097      1\n",
       "36.5189      1\n",
       "37.3669      1\n",
       "40.3416      1\n",
       "40.9835      1\n",
       "37.3796      1\n",
       "30.6838      1\n",
       "37.288       1\n",
       "43.7797      1\n",
       "41.1402      1\n",
       "31.3701      1\n",
       "45.4055      1\n",
       "38.85        1\n",
       "34.0458      1\n",
       "31.3954      1\n",
       "45.2652      1\n",
       "39.6484      1\n",
       "34.8455      1\n",
       "41.8505      1\n",
       "35.7409      1\n",
       "43.9933      1\n",
       "31.5507      1\n",
       "30.4373      1\n",
       "24.7546      1\n",
       "35.7411      1\n",
       "Name: inc_angle, Length: 879, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['inc_angle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['band_1', 'band_2', 'id', 'inc_angle', 'is_iceberg'], dtype='object')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_imgs(df):\n",
    "    \"\"\"\n",
    "    basic function for reshaping and rescaling data as images\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        imgs.append(np.dstack((a, b, c)))\n",
    "\n",
    "    return np.array(imgs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= get_scaled_imgs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424, 4)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_scaled_imgs(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1604, 75, 75, 3)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data['is_iceberg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1604,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=30, width_shift_range=0.2,\n",
    "                             height_shift_range=0.2, brightness_range=None, \n",
    "                             shear_range=0.2, zoom_range= 0.2, channel_shift_range=0.0, \n",
    "                             fill_mode= 'nearest', horizontal_flip=True, vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1604"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = datagen.flow(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we have to take incidence angle into consideration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "def datagenerator(X1, X2, y):\n",
    "    genX1 = datagen.flow(X1,y,  batch_size=batch_size,seed=666)\n",
    "    genX2 = datagen.flow(X1,X2, batch_size=batch_size,seed=666)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['band_1', 'band_2', 'id', 'inc_angle', 'is_iceberg'], dtype='object')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will replace the null values in the incidence angle with 0\n",
    "data['inc_angle'].replace('na', 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = data['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set  =  datagenerator(X_train, X2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1604"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object datagenerator at 0x000002F23DD04620>\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set = datagen.flow(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1604"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(training_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "32\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(8*2**i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_convnet():\n",
    "    #Build keras model\n",
    "    \n",
    "    model=Sequential()\n",
    "    pic_input = Input(shape=(75, 75, 3))\n",
    "    ang_input = Input(shape=(1,))\n",
    "    \n",
    "    # CNN 1\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape = (pic_input,ang_input)))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 2\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # CNN 3\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #CNN 4\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "     # You must flatten the data for the dense layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Dense 1\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Dense 2\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = Adam(lr=0.001, decay=0.0)    \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, concatenate, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Dropout, GlobalMaxPooling2D\n",
    "\n",
    "def basic_convnet2():\n",
    "    pic_input = Input(shape=(75, 75, 3))\n",
    "    ang_input = Input(shape=(1,))\n",
    "\n",
    "    cnn = BatchNormalization()(pic_input)\n",
    "    for i in range(4):\n",
    "        cnn = Conv2D(8*2**i, kernel_size = (3,3), activation='relu')(cnn)\n",
    "        cnn = MaxPooling2D((2,2))(cnn)\n",
    "        #cnn = Dropout(0.2)(cnn)\n",
    "    cnn = GlobalMaxPooling2D()(cnn)\n",
    "    cnn = concatenate([cnn,ang_input])\n",
    "    cnn = Dense(32,activation='relu')(cnn)\n",
    "    cnn = Dropout(0.2)(cnn)\n",
    "    cnn = Dense(1, activation = 'sigmoid')(cnn)\n",
    "\n",
    "    simple_cnn = Model(inputs=[pic_input,ang_input],outputs=cnn)\n",
    "\n",
    "    simple_cnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return simple_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_convnet3():\n",
    "    pic_input = Input(shape=(75, 75, 3))\n",
    "    ang_input = Input(shape=(1,))\n",
    "\n",
    "    cnn = BatchNormalization()(pic_input)\n",
    "    for i in range(4):\n",
    "        cnn = Conv2D(8*2**i, kernel_size = (3,3), activation='relu')(cnn)\n",
    "        cnn = MaxPooling2D((2,2))(cnn)\n",
    "        #cnn = Dropout(0.2)(cnn)\n",
    "    cnn = GlobalMaxPooling2D()(cnn)\n",
    "    cnn = concatenate([cnn,ang_input])\n",
    "    cnn = Dense(32,activation='relu')(cnn)\n",
    "    #cnn = Dropout(0.2)(cnn)\n",
    "    cnn = Dense(1, activation = 'sigmoid')(cnn)\n",
    "\n",
    "    simple_cnn = Model(inputs=[pic_input,ang_input],outputs=cnn)\n",
    "\n",
    "    simple_cnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return simple_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vggmodel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\varshith\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "vgg_model = vggmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 75, 75, 64)   1792        input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 75, 75, 64)   36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 37, 37, 64)   0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 37, 37, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 37, 37, 128)  147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 18, 18, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 18, 18, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 18, 18, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 18, 18, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 9, 9, 256)    0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 9, 9, 512)    1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 9, 9, 512)    2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 9, 9, 512)    2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 4, 4, 512)    0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 4, 4, 512)    2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 4, 4, 512)    2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 4, 4, 512)    2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 2, 2, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "angle (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_12 (Global (None, 512)          0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            2           angle[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 513)          0           global_max_pooling2d_12[0][0]    \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 512)          263168      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512)          0           fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 512)          262656      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 512)          0           fc3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1)            513         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 15,241,027\n",
      "Trainable params: 15,241,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/25 [===============================] - 12s 445ms/step - loss: 0.9704 - acc: 0.5707\n",
      "Epoch 2/100\n",
      "26/25 [===============================] - 8s 298ms/step - loss: 0.6203 - acc: 0.6835\n",
      "Epoch 3/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.4712 - acc: 0.7912\n",
      "Epoch 4/100\n",
      "26/25 [===============================] - 8s 302ms/step - loss: 0.4119 - acc: 0.8156\n",
      "Epoch 5/100\n",
      "26/25 [===============================] - 8s 298ms/step - loss: 0.3771 - acc: 0.8297\n",
      "Epoch 6/100\n",
      "26/25 [===============================] - 8s 298ms/step - loss: 0.3241 - acc: 0.8565\n",
      "Epoch 7/100\n",
      "26/25 [===============================] - 8s 302ms/step - loss: 0.3255 - acc: 0.8373\n",
      "Epoch 8/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.2948 - acc: 0.8658\n",
      "Epoch 9/100\n",
      "26/25 [===============================] - 8s 298ms/step - loss: 0.2751 - acc: 0.8766\n",
      "Epoch 10/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.2810 - acc: 0.8802\n",
      "Epoch 11/100\n",
      "26/25 [===============================] - 8s 298ms/step - loss: 0.2721 - acc: 0.8772\n",
      "Epoch 12/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.2739 - acc: 0.8722\n",
      "Epoch 13/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.3147 - acc: 0.8502\n",
      "Epoch 14/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2628 - acc: 0.8875\n",
      "Epoch 15/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2416 - acc: 0.8896\n",
      "Epoch 16/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.3094 - acc: 0.8601\n",
      "Epoch 17/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2535 - acc: 0.8869\n",
      "Epoch 18/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.2265 - acc: 0.8995\n",
      "Epoch 19/100\n",
      "26/25 [===============================] - 8s 302ms/step - loss: 0.2447 - acc: 0.8941\n",
      "Epoch 20/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2487 - acc: 0.8962\n",
      "Epoch 21/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.2227 - acc: 0.9049\n",
      "Epoch 22/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2310 - acc: 0.8926\n",
      "Epoch 23/100\n",
      "26/25 [===============================] - 8s 304ms/step - loss: 0.2144 - acc: 0.9091\n",
      "Epoch 24/100\n",
      "26/25 [===============================] - 8s 303ms/step - loss: 0.2111 - acc: 0.9157\n",
      "Epoch 25/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1970 - acc: 0.9218\n",
      "Epoch 26/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2171 - acc: 0.9061\n",
      "Epoch 27/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2029 - acc: 0.9127\n",
      "Epoch 28/100\n",
      "26/25 [===============================] - 8s 301ms/step - loss: 0.1942 - acc: 0.9212\n",
      "Epoch 29/100\n",
      "26/25 [===============================] - 8s 304ms/step - loss: 0.2028 - acc: 0.9145\n",
      "Epoch 30/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.2137 - acc: 0.9101\n",
      "Epoch 31/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2243 - acc: 0.8938\n",
      "Epoch 32/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2408 - acc: 0.8887\n",
      "Epoch 33/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2148 - acc: 0.9025\n",
      "Epoch 34/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2118 - acc: 0.9059\n",
      "Epoch 35/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.2052 - acc: 0.9067\n",
      "Epoch 36/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1783 - acc: 0.9200\n",
      "Epoch 37/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1831 - acc: 0.9254\n",
      "Epoch 38/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1773 - acc: 0.9260\n",
      "Epoch 39/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.1753 - acc: 0.9209\n",
      "Epoch 40/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2564 - acc: 0.8875\n",
      "Epoch 41/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1903 - acc: 0.9242\n",
      "Epoch 42/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1696 - acc: 0.9308\n",
      "Epoch 43/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1852 - acc: 0.9257\n",
      "Epoch 44/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.2230 - acc: 0.9059\n",
      "Epoch 45/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.2019 - acc: 0.9133\n",
      "Epoch 46/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1621 - acc: 0.9380\n",
      "Epoch 47/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1523 - acc: 0.9338\n",
      "Epoch 48/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1614 - acc: 0.9386\n",
      "Epoch 49/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1784 - acc: 0.9245\n",
      "Epoch 50/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.1665 - acc: 0.9209\n",
      "Epoch 51/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1885 - acc: 0.9164\n",
      "Epoch 52/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1597 - acc: 0.9392\n",
      "Epoch 53/100\n",
      "26/25 [===============================] - 8s 302ms/step - loss: 0.1432 - acc: 0.9440\n",
      "Epoch 54/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1478 - acc: 0.9404\n",
      "Epoch 55/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.1482 - acc: 0.9404\n",
      "Epoch 56/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1363 - acc: 0.9446\n",
      "Epoch 57/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.1381 - acc: 0.9464\n",
      "Epoch 58/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1118 - acc: 0.9567\n",
      "Epoch 59/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1614 - acc: 0.9287\n",
      "Epoch 60/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.1521 - acc: 0.9302\n",
      "Epoch 61/100\n",
      "26/25 [===============================] - 8s 301ms/step - loss: 0.1323 - acc: 0.9446\n",
      "Epoch 62/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.1492 - acc: 0.9341\n",
      "Epoch 63/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1458 - acc: 0.9374\n",
      "Epoch 64/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1230 - acc: 0.9452\n",
      "Epoch 65/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1082 - acc: 0.9543\n",
      "Epoch 66/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1036 - acc: 0.9579\n",
      "Epoch 67/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.1281 - acc: 0.9488\n",
      "Epoch 68/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1129 - acc: 0.9543\n",
      "Epoch 69/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1248 - acc: 0.9525\n",
      "Epoch 70/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0932 - acc: 0.9603\n",
      "Epoch 71/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1202 - acc: 0.9501\n",
      "Epoch 72/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1028 - acc: 0.9591\n",
      "Epoch 73/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1149 - acc: 0.9579\n",
      "Epoch 74/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0948 - acc: 0.9663\n",
      "Epoch 75/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0936 - acc: 0.9603\n",
      "Epoch 76/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0869 - acc: 0.9657\n",
      "Epoch 77/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1159 - acc: 0.9567\n",
      "Epoch 78/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0754 - acc: 0.9699\n",
      "Epoch 79/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.1005 - acc: 0.9627\n",
      "Epoch 80/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0962 - acc: 0.9627\n",
      "Epoch 81/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0713 - acc: 0.9759\n",
      "Epoch 82/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0977 - acc: 0.9633\n",
      "Epoch 83/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.0951 - acc: 0.9639\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0809 - acc: 0.9687\n",
      "Epoch 85/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0863 - acc: 0.9606\n",
      "Epoch 86/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.1539 - acc: 0.9320\n",
      "Epoch 87/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0952 - acc: 0.9645\n",
      "Epoch 88/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0973 - acc: 0.9621\n",
      "Epoch 89/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0744 - acc: 0.9711\n",
      "Epoch 90/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0726 - acc: 0.9729\n",
      "Epoch 91/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0794 - acc: 0.9669\n",
      "Epoch 92/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0959 - acc: 0.9609\n",
      "Epoch 93/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0944 - acc: 0.9615\n",
      "Epoch 94/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0626 - acc: 0.9789\n",
      "Epoch 95/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0625 - acc: 0.9735\n",
      "Epoch 96/100\n",
      "26/25 [===============================] - 8s 299ms/step - loss: 0.0736 - acc: 0.9717\n",
      "Epoch 97/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0810 - acc: 0.9729\n",
      "Epoch 98/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0837 - acc: 0.9681\n",
      "Epoch 99/100\n",
      "26/25 [===============================] - 8s 300ms/step - loss: 0.0588 - acc: 0.9777\n",
      "Epoch 100/100\n",
      "26/25 [===============================] - 8s 303ms/step - loss: 0.0722 - acc: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f24b668e48>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.fit_generator(training_set,steps_per_epoch = len(X_train) / 64, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basic_convnet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 75, 75, 3)    12          input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 73, 73, 8)    224         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 36, 36, 8)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 34, 34, 16)   1168        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 17, 17, 16)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 15, 15, 32)   4640        max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 7, 7, 32)     0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 5, 5, 64)     18496       max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 2, 2, 64)     0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_5 (GlobalM (None, 64)           0           max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 65)           0           global_max_pooling2d_5[0][0]     \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           2112        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            33          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,685\n",
      "Trainable params: 26,679\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = basic_convnet3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 75, 75, 3)    12          input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 73, 73, 8)    224         batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 36, 36, 8)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 34, 34, 16)   1168        max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 17, 17, 16)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 15, 15, 32)   4640        max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 7, 7, 32)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 5, 5, 64)     18496       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 2, 2, 64)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_7 (GlobalM (None, 64)           0           max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 65)           0           global_max_pooling2d_7[0][0]     \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           2112        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            33          dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 26,685\n",
      "Trainable params: 26,679\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/25 [===============================] - 4s 143ms/step - loss: 3.1324 - acc: 0.4612\n",
      "Epoch 2/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 1.1024 - acc: 0.5244\n",
      "Epoch 3/100\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.6926 - acc: 0.5650\n",
      "Epoch 4/100\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.6098 - acc: 0.6285\n",
      "Epoch 5/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.5937 - acc: 0.6612\n",
      "Epoch 6/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.5941 - acc: 0.6507\n",
      "Epoch 7/100\n",
      "26/25 [===============================] - 3s 130ms/step - loss: 0.5658 - acc: 0.7075\n",
      "Epoch 8/100\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.5541 - acc: 0.7067\n",
      "Epoch 9/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.5331 - acc: 0.7238\n",
      "Epoch 10/100\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.5387 - acc: 0.7154\n",
      "Epoch 11/100\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.5424 - acc: 0.7307\n",
      "Epoch 12/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.5347 - acc: 0.7239\n",
      "Epoch 13/100\n",
      "26/25 [===============================] - 3s 130ms/step - loss: 0.5308 - acc: 0.7265\n",
      "Epoch 14/100\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.5369 - acc: 0.7209\n",
      "Epoch 15/100\n",
      "26/25 [===============================] - 3s 132ms/step - loss: 0.5014 - acc: 0.7430\n",
      "Epoch 16/100\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.5206 - acc: 0.7319\n",
      "Epoch 17/100\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.4836 - acc: 0.7705\n",
      "Epoch 18/100\n",
      "26/25 [===============================] - 3s 129ms/step - loss: 0.4646 - acc: 0.7735\n",
      "Epoch 19/100\n",
      "26/25 [===============================] - 4s 138ms/step - loss: 0.4575 - acc: 0.7747\n",
      "Epoch 20/100\n",
      "26/25 [===============================] - 3s 132ms/step - loss: 0.4591 - acc: 0.7717\n",
      "Epoch 21/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.4033 - acc: 0.8146\n",
      "Epoch 22/100\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.4051 - acc: 0.7987\n",
      "Epoch 23/100\n",
      "26/25 [===============================] - 3s 133ms/step - loss: 0.4346 - acc: 0.7775\n",
      "Epoch 24/100\n",
      "26/25 [===============================] - 3s 127ms/step - loss: 0.3838 - acc: 0.8243\n",
      "Epoch 25/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3850 - acc: 0.8222\n",
      "Epoch 26/100\n",
      "26/25 [===============================] - 3s 127ms/step - loss: 0.3645 - acc: 0.8423\n",
      "Epoch 27/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3895 - acc: 0.8210\n",
      "Epoch 28/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3907 - acc: 0.8285\n",
      "Epoch 29/100\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3504 - acc: 0.8471\n",
      "Epoch 30/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3793 - acc: 0.8327\n",
      "Epoch 31/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.3738 - acc: 0.8228\n",
      "Epoch 32/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3674 - acc: 0.8291\n",
      "Epoch 33/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3886 - acc: 0.8318\n",
      "Epoch 34/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3477 - acc: 0.8393\n",
      "Epoch 35/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3285 - acc: 0.8483\n",
      "Epoch 36/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3294 - acc: 0.8481\n",
      "Epoch 37/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3136 - acc: 0.8628\n",
      "Epoch 38/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3276 - acc: 0.8568\n",
      "Epoch 39/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3380 - acc: 0.8442\n",
      "Epoch 40/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3401 - acc: 0.8405\n",
      "Epoch 41/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3237 - acc: 0.8529\n",
      "Epoch 42/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3083 - acc: 0.8712\n",
      "Epoch 43/100\n",
      "26/25 [===============================] - 4s 150ms/step - loss: 0.3533 - acc: 0.8310\n",
      "Epoch 44/100\n",
      "26/25 [===============================] - 3s 127ms/step - loss: 0.3308 - acc: 0.8496\n",
      "Epoch 45/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3631 - acc: 0.8319\n",
      "Epoch 46/100\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.3289 - acc: 0.8459\n",
      "Epoch 47/100\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3074 - acc: 0.8682\n",
      "Epoch 48/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3240 - acc: 0.8361\n",
      "Epoch 49/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3180 - acc: 0.8628\n",
      "Epoch 50/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2965 - acc: 0.8604\n",
      "Epoch 51/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3073 - acc: 0.8571\n",
      "Epoch 52/100\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3330 - acc: 0.8453\n",
      "Epoch 53/100\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.3317 - acc: 0.8511\n",
      "Epoch 54/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3306 - acc: 0.8574\n",
      "Epoch 55/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3090 - acc: 0.8532\n",
      "Epoch 56/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3052 - acc: 0.8580\n",
      "Epoch 57/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3073 - acc: 0.8706\n",
      "Epoch 58/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.3592 - acc: 0.8268\n",
      "Epoch 59/100\n",
      "26/25 [===============================] - 3s 134ms/step - loss: 0.3051 - acc: 0.8550\n",
      "Epoch 60/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3205 - acc: 0.8658\n",
      "Epoch 61/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.3016 - acc: 0.8676\n",
      "Epoch 62/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2905 - acc: 0.8589\n",
      "Epoch 63/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3028 - acc: 0.8670\n",
      "Epoch 64/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2781 - acc: 0.8658\n",
      "Epoch 65/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.2846 - acc: 0.8772\n",
      "Epoch 66/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3126 - acc: 0.8433\n",
      "Epoch 67/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3087 - acc: 0.8728\n",
      "Epoch 68/100\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.3265 - acc: 0.8405\n",
      "Epoch 69/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3059 - acc: 0.8571\n",
      "Epoch 70/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3101 - acc: 0.8730\n",
      "Epoch 71/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2870 - acc: 0.8646\n",
      "Epoch 72/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3015 - acc: 0.8568\n",
      "Epoch 73/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2926 - acc: 0.8736\n",
      "Epoch 74/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3079 - acc: 0.8544\n",
      "Epoch 75/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3238 - acc: 0.8490\n",
      "Epoch 76/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3130 - acc: 0.8556\n",
      "Epoch 77/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3201 - acc: 0.8559\n",
      "Epoch 78/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3026 - acc: 0.8571\n",
      "Epoch 79/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.3061 - acc: 0.8607\n",
      "Epoch 80/100\n",
      "26/25 [===============================] - 4s 135ms/step - loss: 0.2733 - acc: 0.8748\n",
      "Epoch 81/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3167 - acc: 0.8493\n",
      "Epoch 82/100\n",
      "26/25 [===============================] - 3s 127ms/step - loss: 0.2756 - acc: 0.8655\n",
      "Epoch 83/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2932 - acc: 0.8625\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/25 [===============================] - 3s 126ms/step - loss: 0.3176 - acc: 0.8587\n",
      "Epoch 85/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.3119 - acc: 0.8514\n",
      "Epoch 86/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2669 - acc: 0.8748\n",
      "Epoch 87/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3172 - acc: 0.8565\n",
      "Epoch 88/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2858 - acc: 0.8736\n",
      "Epoch 89/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.3000 - acc: 0.8625\n",
      "Epoch 90/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.2996 - acc: 0.8545\n",
      "Epoch 91/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.2853 - acc: 0.8760\n",
      "Epoch 92/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2741 - acc: 0.8772\n",
      "Epoch 93/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.2923 - acc: 0.8712\n",
      "Epoch 94/100\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.3096 - acc: 0.8529\n",
      "Epoch 95/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3027 - acc: 0.8694\n",
      "Epoch 96/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2933 - acc: 0.8598\n",
      "Epoch 97/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2737 - acc: 0.8833\n",
      "Epoch 98/100\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3021 - acc: 0.8634\n",
      "Epoch 99/100\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.2988 - acc: 0.8673\n",
      "Epoch 100/100\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3075 - acc: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f0be2e2e80>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_set,steps_per_epoch = len(X_train) / 64, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "26/25 [===============================] - 5s 205ms/step - loss: 1.3889 - acc: 0.4972\n",
      "Epoch 2/80\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.6429 - acc: 0.5882\n",
      "Epoch 3/80\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.5972 - acc: 0.6489\n",
      "Epoch 4/80\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.5719 - acc: 0.6974\n",
      "Epoch 5/80\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.5335 - acc: 0.7497\n",
      "Epoch 6/80\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.5197 - acc: 0.7536\n",
      "Epoch 7/80\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.4962 - acc: 0.7675\n",
      "Epoch 8/80\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.4781 - acc: 0.7735\n",
      "Epoch 9/80\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.4628 - acc: 0.7771\n",
      "Epoch 10/80\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.5032 - acc: 0.7594\n",
      "Epoch 11/80\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.4400 - acc: 0.8014\n",
      "Epoch 12/80\n",
      "26/25 [===============================] - 3s 129ms/step - loss: 0.4617 - acc: 0.7765\n",
      "Epoch 13/80\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.4762 - acc: 0.7576\n",
      "Epoch 14/80\n",
      "26/25 [===============================] - 3s 129ms/step - loss: 0.4316 - acc: 0.7852\n",
      "Epoch 15/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.4247 - acc: 0.8026\n",
      "Epoch 16/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.4210 - acc: 0.8044\n",
      "Epoch 17/80\n",
      "26/25 [===============================] - 3s 120ms/step - loss: 0.3903 - acc: 0.8237\n",
      "Epoch 18/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3820 - acc: 0.8255\n",
      "Epoch 19/80\n",
      "26/25 [===============================] - 3s 132ms/step - loss: 0.3706 - acc: 0.8315\n",
      "Epoch 20/80\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.3942 - acc: 0.8120\n",
      "Epoch 21/80\n",
      "26/25 [===============================] - 3s 133ms/step - loss: 0.3925 - acc: 0.8066\n",
      "Epoch 22/80\n",
      "26/25 [===============================] - 4s 139ms/step - loss: 0.3290 - acc: 0.8471\n",
      "Epoch 23/80\n",
      "26/25 [===============================] - 3s 127ms/step - loss: 0.3789 - acc: 0.8216\n",
      "Epoch 24/80\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.3454 - acc: 0.8385\n",
      "Epoch 25/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3486 - acc: 0.8294\n",
      "Epoch 26/80\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2928 - acc: 0.8616\n",
      "Epoch 27/80\n",
      "26/25 [===============================] - 3s 129ms/step - loss: 0.3106 - acc: 0.8598\n",
      "Epoch 28/80\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.2875 - acc: 0.8682\n",
      "Epoch 29/80\n",
      "26/25 [===============================] - 3s 127ms/step - loss: 0.4342 - acc: 0.8054\n",
      "Epoch 30/80\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.3778 - acc: 0.8093\n",
      "Epoch 31/80\n",
      "26/25 [===============================] - 3s 120ms/step - loss: 0.3427 - acc: 0.8499\n",
      "Epoch 32/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3243 - acc: 0.8493\n",
      "Epoch 33/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3359 - acc: 0.8526\n",
      "Epoch 34/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3392 - acc: 0.8379\n",
      "Epoch 35/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.2954 - acc: 0.8688\n",
      "Epoch 36/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3038 - acc: 0.8592\n",
      "Epoch 37/80\n",
      "26/25 [===============================] - 3s 120ms/step - loss: 0.2735 - acc: 0.8869\n",
      "Epoch 38/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.4234 - acc: 0.7838\n",
      "Epoch 39/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3304 - acc: 0.8520\n",
      "Epoch 40/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.2784 - acc: 0.8845\n",
      "Epoch 41/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.2970 - acc: 0.8652\n",
      "Epoch 42/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2914 - acc: 0.8710\n",
      "Epoch 43/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3214 - acc: 0.8487\n",
      "Epoch 44/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2574 - acc: 0.8845\n",
      "Epoch 45/80\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2797 - acc: 0.8736\n",
      "Epoch 46/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2843 - acc: 0.8748\n",
      "Epoch 47/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3108 - acc: 0.8601\n",
      "Epoch 48/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3131 - acc: 0.8571\n",
      "Epoch 49/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.3024 - acc: 0.8617\n",
      "Epoch 50/80\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.2893 - acc: 0.8706\n",
      "Epoch 51/80\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2837 - acc: 0.8718\n",
      "Epoch 52/80\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.2961 - acc: 0.8718\n",
      "Epoch 53/80\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.2904 - acc: 0.8718\n",
      "Epoch 54/80\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2767 - acc: 0.8766\n",
      "Epoch 55/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.2646 - acc: 0.8863\n",
      "Epoch 56/80\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.2667 - acc: 0.8848\n",
      "Epoch 57/80\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.2492 - acc: 0.8953\n",
      "Epoch 58/80\n",
      "26/25 [===============================] - 3s 129ms/step - loss: 0.2786 - acc: 0.8851\n",
      "Epoch 59/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2810 - acc: 0.8820\n",
      "Epoch 60/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2597 - acc: 0.8887\n",
      "Epoch 61/80\n",
      "26/25 [===============================] - 3s 125ms/step - loss: 0.2519 - acc: 0.8887\n",
      "Epoch 62/80\n",
      "26/25 [===============================] - 4s 139ms/step - loss: 0.2660 - acc: 0.8782\n",
      "Epoch 63/80\n",
      "26/25 [===============================] - 3s 130ms/step - loss: 0.2629 - acc: 0.8869\n",
      "Epoch 64/80\n",
      "26/25 [===============================] - 3s 131ms/step - loss: 0.2838 - acc: 0.8716\n",
      "Epoch 65/80\n",
      "26/25 [===============================] - 4s 136ms/step - loss: 0.2799 - acc: 0.8782\n",
      "Epoch 66/80\n",
      "26/25 [===============================] - 3s 131ms/step - loss: 0.2643 - acc: 0.8866\n",
      "Epoch 67/80\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2937 - acc: 0.8692\n",
      "Epoch 68/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.3141 - acc: 0.8641\n",
      "Epoch 69/80\n",
      "26/25 [===============================] - 3s 120ms/step - loss: 0.2827 - acc: 0.8748\n",
      "Epoch 70/80\n",
      "26/25 [===============================] - 3s 120ms/step - loss: 0.2485 - acc: 0.8911\n",
      "Epoch 71/80\n",
      "26/25 [===============================] - 3s 128ms/step - loss: 0.2719 - acc: 0.8808\n",
      "Epoch 72/80\n",
      "26/25 [===============================] - 3s 126ms/step - loss: 0.2678 - acc: 0.8875\n",
      "Epoch 73/80\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2294 - acc: 0.8989\n",
      "Epoch 74/80\n",
      "26/25 [===============================] - 3s 120ms/step - loss: 0.2534 - acc: 0.9031\n",
      "Epoch 75/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2944 - acc: 0.8664\n",
      "Epoch 76/80\n",
      "26/25 [===============================] - 3s 124ms/step - loss: 0.2636 - acc: 0.8869\n",
      "Epoch 77/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2433 - acc: 0.8995\n",
      "Epoch 78/80\n",
      "26/25 [===============================] - 3s 123ms/step - loss: 0.2420 - acc: 0.9019\n",
      "Epoch 79/80\n",
      "26/25 [===============================] - 3s 122ms/step - loss: 0.2745 - acc: 0.8863\n",
      "Epoch 80/80\n",
      "26/25 [===============================] - 3s 121ms/step - loss: 0.2425 - acc: 0.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ef44a32438>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(training_set,steps_per_epoch = len(X_train) / 64, epochs= 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_angle = test['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_angle = np.array(test_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.9664    , 32.61507205, 37.50543316, ..., 39.5032    ,\n",
       "       33.638     , 36.75818109])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict([X_test, test_angle])\n",
    "#preds2 = model.predict([X_test, test_angle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3 = vgg_model.predict([X_test, test_angle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50235146],\n",
       "       [0.46587917],\n",
       "       [0.01896   ],\n",
       "       ...,\n",
       "       [0.17120579],\n",
       "       [0.98827994],\n",
       "       [0.05308677]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18931365],\n",
       "       [0.6697147 ],\n",
       "       [0.17065553],\n",
       "       ...,\n",
       "       [0.07307102],\n",
       "       [0.9967675 ],\n",
       "       [0.12886   ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = model2.predict([X_test, test_angle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['is_iceberg'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('very_basic_100_with_one_dropout_layer.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['is_iceberg'] = preds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    " sub.to_csv('vgg100flipsx_.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
